### Workshop Learning Objectives (*Natural Language Processing*)

#### Session 1
1. Describe how NLP is at the inter-section of multiple disciplines.
2. Operationally define of natural language processing.
3. Discuss the purpose of NLP and what problems it tries to solve.
4. List the five types of applications of NLP.
5. Disucss how language is ambiguous and give an example.
6. Utilize and implement NLP with Transformers.
7. Discuss PyTorch.
8. Briefly describe a tranformer.
9. Discuss the results and interesting outcomes or surprises.
10. Discuss the purpose and importance of text/data pre-processing and data cleaning.
11. Describe tokenization.
12. Discuss cleaning options and examples.
13. Describe normalization with stemming and lemmatization and the purpose.
14. Describe one-hot encoding and its purpose.
15. Discuss NLTK.
16. Implement tokenization, case normalization, and stop word removal.
17. Implemeting data stemming.
18. Implement data one-hot encoding.

#### Session 2
1. Implement the Word2Vec model demo.
2. Describe word embeddings and the purpose.
3. Discuss the Word2Vec model.
4. Discuss how words can be described as vector mappings.
5. Discuss a multidimensional embedding (embedder).
6. Discuss the results and interesting outcomes or surprises.
7. Describe the CBOW versus Skip-Gram architectures.
8. Discuss the essence of word embedding.
9. Implement your own word embedding training.
10. Implement training word vectors on different data sets.
11. Discuss the results and interesting outcomes or surprises.
