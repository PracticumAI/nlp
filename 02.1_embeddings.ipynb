{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)\n",
    "***\n",
    "# *Practicum AI:* NLP - Embeddings\n",
    "\n",
    "These exercises adapted from Baig et al. (2020) <i>The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (Exercises 4.01 - 4.06, page 159).\n",
    "\n",
    "(15 Minutes: Exercises 4.05 - 4.06)\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "In this exercise, we explore word embeddings.  So, what exactly are word embeddings? In short, they are vector representations of a particular word.  Word embeddings capture the context of a word in a document, semantic and syntactic similarity, as well as relation to other words.\n",
    "\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Our Own Embeddings - Page 197\n",
    "Load the dataset from the data folder.  The [text8 corpus](http://mattmahoney.net/dc/textdata.html) contains the first billion characters from Wikipedia as of March 3, 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = word2vec.Text8Corpus(\"data/text8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure reproducible results, set random seed to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train our first word embedding by using the word2Vec method.  Training times vary but 2 to 3 minutes is common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the vector/embedding for the word \"animal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.28147197e+00  4.93714213e-02 -1.77742636e+00  7.55727291e-01\n",
      " -4.48607475e-01 -1.61682606e+00  6.28471494e-01  1.29946005e+00\n",
      " -1.47697222e+00  7.33656824e-01 -2.50913620e-01  1.51851982e-01\n",
      " -8.39449286e-01  2.08915448e+00 -1.26336062e+00 -2.56653976e+00\n",
      "  5.14868915e-01  7.32167482e-01 -2.00053260e-01  5.38162589e-01\n",
      "  7.24335492e-01 -2.29516530e+00  1.24233079e+00  1.90678668e+00\n",
      "  2.64481211e+00 -3.21866304e-01 -2.15857774e-01  8.05656314e-01\n",
      "  7.09271729e-01 -3.06913555e-02  1.01351726e+00  1.23749733e+00\n",
      "  1.07249832e+00 -3.15461636e+00 -6.08641505e-01 -2.17098817e-01\n",
      "  1.12186813e+00  1.78734243e+00 -1.53762472e+00 -8.31309557e-02\n",
      "  5.96177101e-01 -7.12612689e-01 -6.29826248e-01  2.86765814e+00\n",
      " -1.24110842e+00  3.18110204e+00 -1.22431970e+00  7.18615949e-01\n",
      "  2.28058863e-02  1.10605106e-01 -3.84237826e-01 -1.09326792e+00\n",
      " -1.59575546e+00  1.34581447e+00  1.97974071e-01  1.38159752e+00\n",
      "  1.04777730e+00  1.09187233e+00 -6.55379534e-01 -4.87283587e-01\n",
      " -3.02258093e-04 -3.09790659e+00  3.12558860e-01 -7.55995929e-01\n",
      "  6.53878033e-01 -1.42505515e+00 -6.84361219e-01 -1.98722982e+00\n",
      "  2.03627542e-01 -2.62332344e+00 -1.22702301e+00 -7.83539638e-02\n",
      "  5.55929661e-01 -5.22257209e-01 -2.06089884e-01 -8.56916159e-02\n",
      "  1.27778232e-01  2.00050163e+00  8.79916787e-01 -3.12977016e-01\n",
      "  9.90636051e-01  7.68502578e-02  4.79292810e-01  2.22123456e+00\n",
      "  3.26232046e-01 -6.47940338e-01  5.29664755e-01 -8.46596301e-01\n",
      " -9.89370763e-01 -2.73317963e-01 -7.79004514e-01  9.23403680e-01\n",
      " -1.91273856e+00 -5.86819768e-01 -1.96264207e+00  9.31627750e-01\n",
      "  1.45146585e+00 -2.15020943e+00 -7.38836050e-01 -5.00052929e-01]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv[\"animal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the size of the vector?  How many dimensions does it have?  The length of the vector is a hyperparameter we can change.  The default is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv[\"animal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `most_similar()` method shows terms that are like the target word.  This method uses cosine similarity to return the words with the highest values.\n",
    "\n",
    "Cosine similarity is a popular NLP method for approximating how similar two word/sentence vectors are. The intuition behind cosine similarity is relatively straight forward, we simply use the cosine of the angle between the two vectors to quantify how similar two documents are [(Paul Minogue)](https://paulminogue.com/posts/0de56ac8-914a-4056-9bf9-005572959bb1).  \n",
    "\n",
    "Cosine similarity works well here because we expect similar words to be located close to each other in multi-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animals', 0.7239352464675903),\n",
       " ('insect', 0.7155537009239197),\n",
       " ('ants', 0.6823122501373291),\n",
       " ('insects', 0.679811954498291),\n",
       " ('aquatic', 0.660001814365387),\n",
       " ('organism', 0.656354546546936),\n",
       " ('eating', 0.6549410820007324),\n",
       " ('mammal', 0.6496347188949585),\n",
       " ('human', 0.6453425288200378),\n",
       " ('humans', 0.642937421798706)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"animal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the term *happiness*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('humanity', 0.7880685329437256),\n",
       " ('goodness', 0.7656909227371216),\n",
       " ('compassion', 0.7424624562263489),\n",
       " ('dignity', 0.7383203506469727),\n",
       " ('fear', 0.7318388819694519),\n",
       " ('pleasure', 0.7316447496414185),\n",
       " ('perfection', 0.7248966693878174),\n",
       " ('salvation', 0.7177927494049072),\n",
       " ('mankind', 0.7145527601242065),\n",
       " ('immortality', 0.7055302262306213)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"happiness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semantic Regularities in Word Embeddings\n",
    "\n",
    "Using the `most_similar()` method, we can add and subtract vectors.  For example, we can add the 'woman' and 'king' vectors, subtract 'man' from the result, and then check the top 5 words most similar to the resulting vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6914654970169067),\n",
       " ('princess', 0.6395758986473083),\n",
       " ('prince', 0.6220191717147827),\n",
       " ('daughter', 0.6123440265655518),\n",
       " ('empress', 0.6098198294639587)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'>The top result is 'queen'.  This looks good!</div>\n",
    "<br>\n",
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'>Let's do another vector calculation: uncle - man + woman = what?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wife', 0.8296380043029785),\n",
       " ('aunt', 0.8148874640464783),\n",
       " ('niece', 0.8077722787857056),\n",
       " ('daughter', 0.7944497466087341),\n",
       " ('grandmother', 0.7883173227310181)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['uncle', 'woman'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'> ... 'aunt' sounds about right! </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.05 (Vectors for Phrases) - Page 201\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract the vector for 'get'\n",
    "\n",
    "```python\n",
    "v1 = model.wv['get']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract the vector for 'happy'\n",
    "\n",
    "```python\n",
    "v2 = model.wv['happy']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a new vector as the average of the two vectors\n",
    "\n",
    "```python\n",
    "res1 = (v1 + v2) / 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extract vectors for 'make' and 'merry'\n",
    "\n",
    "```python\n",
    "v1 = model.wv['make']\n",
    "v2 = model.wv['merry']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create a new vector as the average of the two vectors\n",
    "\n",
    "```python\n",
    "res2 = (v1+v2)/2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Find cosine similarity between the two averaged vectors\n",
    "\n",
    "```python\n",
    "model.wv.cosine_similarities(res1, [res2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a cosine similarity of about 0.57.  As this is positive and much higher than 0, it means the model thinks the phrases 'get happy' and 'make merry' are similar in meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Effect of Parameters - 'size' of the Vector\n",
    "\n",
    "The size parameter of the word2vec algorithm is the vector length for each term. The default, as we saw earlier, is 100.  But what happens if we reduce the size of this vector or word embedding?  Will we see any differences in the results? \n",
    "\n",
    "Let's retrain the word embeddings with size set to 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(dataset, size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('son', 0.8133434653282166),\n",
       " ('empress', 0.8022229671478271),\n",
       " ('emperor', 0.7999867796897888),\n",
       " ('archbishop', 0.7950774431228638),\n",
       " ('constantine', 0.7858606576919556)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the word 'queen' is no longer present in the top five results.  A significant reduction in dimensionality has had a significant impact on the results.  The embeddings appear to lack the information they need to fully represent each word in our text. \n",
    "\n",
    "***\n",
    "#### Effect of parameters - Skipgram vs. CBOW\n",
    "\n",
    "The sg argument allows one to select Skipgram (**sg = 1**) or CBOW (**sg = 0**, the default).  Recall that the Skip-gram approach predicts the context words based on the central target word.  This flips the formulation of CBOW, where the context words are used to predict the target word. But how do we choose between the two? What are the benefits of one over the other? To see for ourselves, let's train embeddings using Skip-gram and compare some results with what we had for CBOW. Let's use a relatively rare word (*oeuvre*) to compare the two approaches. Oeuvre, by the way, is the \"body of work of an artist/performer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seminal', 0.7173739671707153),\n",
       " ('baglione', 0.6992780566215515),\n",
       " ('wace', 0.6952950954437256),\n",
       " ('mockery', 0.6938953399658203),\n",
       " ('foxe', 0.687375545501709)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"oeuvre\", topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting list, but none of the words are even close to the meaning of our target word.  Let's retrain with Skip Gram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg = word2vec.Word2Vec(dataset, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('masterful', 0.8323545455932617),\n",
       " ('satiric', 0.8200669288635254),\n",
       " ('masterwork', 0.815832257270813),\n",
       " ('mussorgsky', 0.815514862537384),\n",
       " ('librettos', 0.8108195662498474)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar(\"oeuvre\", topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Skip-gram, the top terms are much closer in meaning (masterful, orchestration, showcasing). This method seems to work better for rare words. But why? The CBOW method smooths over a lot of the distributional statistics by effectively averaging overall context words (remember, all the context terms together go as an input), while Skip-gram does not. When you have a small dataset, the smoothing that's done by CBOW is desirable. If you have a small/moderately sized dataset, and if you are concerned about the representation of rare terms, then Skip-gram is a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.06 (Training Word Vectors on Different Datasets) - Page 205\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the Brown and IMDb movie reviews corpus\n",
    "\n",
    "```python\n",
    "nltk.download('brown')\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "from nltk.corpus import brown, movie_reviews\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract the sentences and words using the .sent() method\n",
    "\n",
    "```python\n",
    "model_brown = word2vec.Word2Vec(brown.sents(), sg = 1)\n",
    "model_movie = word2vec.Word2Vec(movie_reviews.sents(), sg = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Print the five terms most similar to 'money' in the Brown corpus\n",
    "\n",
    "```python\n",
    "model_brown.wv.most_similar('money', topn = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Print the five terms most similar to 'money' in the movie corpus\n",
    "\n",
    "```python\n",
    "model_movie.wv.most_similar('money', topn = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##### Using Pre-Trained Word Vectors\n",
    "\n",
    "Rather than train a model ourselves, the Stanford NLP group has released their pre-trained embeddings to the public.  More information about their work can be found on the [Glove page](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "Let's import the glove2word2vec utility.  As its name suggests, this utility converts GloVe word vectors into word2vec format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_input_file     = 'data/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'data/glove.6B.100d.w2vformat.txt'\n",
    "\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'> Now load the keyed word vectors. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"data/glove.6B.100d.w2vformat.txt\", binary = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'> What words are most similar to 'money'? </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('funds', 0.8508071303367615),\n",
       " ('cash', 0.848483681678772),\n",
       " ('fund', 0.7594833374023438),\n",
       " ('paying', 0.7415367364883423),\n",
       " ('pay', 0.7407673001289368)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar(\"money\", topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'> And how does GloVe do on the king and queen tasks? </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380928039551),\n",
       " ('throne', 0.6755735874176025),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534753799438)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar(positive=['woman', 'king'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bias in Embeddings – A Word of Caution\n",
    "\n",
    "With a few minor exceptions, the embeddings are doing a good job of identifying relationships and regularities in our text data.\n",
    "\n",
    "Let's now see what happens when we do some vector arithmetic on words related to a profession.  Take, for instance, this calculation: doctor - man + woman.  What words are most similar to the resulting vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('child', 0.6149958372116089),\n",
       " ('nurse', 0.6090491414070129),\n",
       " ('teacher', 0.5878923535346985),\n",
       " ('dominatrix', 0.5384681224822998),\n",
       " ('detective', 0.5246642231941223)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'doctor'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'> That's not exactly the kind of results we want.  Doctors are men and women are nurses?</div>\n",
    "<br>\n",
    "<div style='padding: 5px; border-left-style: solid; border-left-color: #65BB7B'>And how does the model do when asked about female intelligence?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pet', 0.6097452640533447),\n",
       " ('odie', 0.567996621131897),\n",
       " ('lingerie', 0.5643869042396545),\n",
       " ('scam', 0.5464061498641968),\n",
       " ('thug', 0.5415985584259033)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'smart'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's awful!  What's happening?  Is the word2vec algorithm sexist?  The short answer is no.  These models only reflect the data used to train them. In other words, the underlying body of text contains the bias, not the algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFRC Python-3.8",
   "language": "python",
   "name": "python3-3.8-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
