{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)\n",
    "***\n",
    "# *Practicum AI:* NLP - Alice Wonderland \n",
    "\n",
    "This exercise adapted from Baig et al. (2020) <i>The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (Activity 4.01 & 4.02, page 176)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading Text Corpora Using NLTK (Data Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #E5C250;border-left-width: 10px;background-color: #fff\"><strong>Tip:</strong> The nltk.download() command, when executed without arguments, does not open the NLTK downloader in a new window, as pictured in the textbook.  The Unix version has a command line interface.  Type 'l' in the NLTK field and hit enter to view the Packages available for install.  As this list is rather long, you will need to hit enter multiple times to scroll through it.  The gutenberg package is in this list.  To install it, type 'd' and hit enter.  Then type 'gutenberg' in the NLTK field and hit enter again.  The software will respond with an installation message.  And finally, type 'q' to exit the downloader.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_raw = nltk.corpus.gutenberg.raw('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_raw[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Activity 4.01 (Text Preprocessing) - Page 176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set the raw text to lowercase\n",
    "\n",
    "```python\n",
    "from nltk import tokenize\n",
    "txt_sents = tokenize.sent_tokenize(alice_raw.lower())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tokenize the sentences\n",
    "\n",
    "```python\n",
    "txt_words = [tokenize.word_tokenize(sent) for sent in txt_sents]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Import punctuation from string module & stop words from NLTK\n",
    "\n",
    "```python\n",
    "from string import punctuation\n",
    "stop_punct = list(punctuation)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_nltk = stopwords.words(\"english\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create variable to contain the stop words: \"--\" and \"said\"\n",
    "\n",
    "```python\n",
    "stop_context = [\"--\", \"said\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create a master list of stop words\n",
    "\n",
    "```python\n",
    "stop_final = stop_punct + stop_nltk + stop_context\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define a function to drop these tokens from any input sequence\n",
    "\n",
    "```python\n",
    "\n",
    "def drop_stop(input_tokens):\n",
    "    return [token for token in input_tokens if token not in stop_final]\n",
    "\n",
    "alice_words_nostop = [drop_stop(sent) for sent in txt_words]\n",
    "print(alice_words_nostop[:2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Use PorterStemmer from NLTK to perform stemming on the result\n",
    "\n",
    "```python\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer_p = PorterStemmer()\n",
    "\n",
    "alice_words_stem = [[stemmer_p.stem(token) for token in sent] for sent in alice_words_nostop]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Print the first five sentences\n",
    "\n",
    "```python\n",
    "print(alice_words_stem[:5])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Activity 4.02 (Text Representation) - Page 210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Print the data you will work with\n",
    "\n",
    "```python\n",
    "print(alice_words_nostop[:3])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train your word embeddings with word2vec\n",
    "\n",
    "```python\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(alice_words_nostop)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Find the 5 terms most similar to rabbit\n",
    "\n",
    "```python\n",
    "model.wv.most_similar(\"rabbit\", topn = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Using a window size of 2, retrain the word vectors\n",
    "\n",
    "```python\n",
    "model = word2vec.Word2Vec(alice_words_nostop, window = 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Find the terms most similar to 'rabbit'\n",
    "\n",
    "```python\n",
    "model.wv.most_similar(\"rabbit\", topn = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Retrain word vectors using the Skip_gram method with window size of 5\n",
    "\n",
    "```python\n",
    "model = word2vec.Word2Vec(alice_words_nostop, window = 5, sg = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Find the terms most similar to 'rabbit'\n",
    "\n",
    "```python\n",
    "model.wv.most_similar(\"rabbit\", topn = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Find the representation for the phrase 'white rabbit' by averaging the vectors for 'white' and 'rabbit'\n",
    "\n",
    "```python\n",
    "v1 = model.wv['white']\n",
    "v2 = model.wv['rabbit']\n",
    "res1 = (v1+v2)/2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Find the representation for the phrase 'mad hatter' by averaging the vectors for 'mad' and 'hatter'\n",
    "\n",
    "```python\n",
    "v1 = model.wv['mad']\n",
    "v2 = model.wv['hatter']\n",
    "res2 = (v1+v2)/2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Find the cosine similarity between these two phrases\n",
    "\n",
    "```python \n",
    "model.wv.cosine_similarities(res1, [res2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Load the pre-train GloVe embeddings of size 100D using the formatted keyed vectors\n",
    "\n",
    "```python\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\n",
    "    \"data/glove.6B.100d.w2vformat.txt\", \n",
    "    binary = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Find representations for 'white rabbit' and 'mad hatter'\n",
    "\n",
    "```python\n",
    "v1 = glove_model['white']\n",
    "v2 = glove_model['rabbit']\n",
    "res1 = (v1+v2)/2\n",
    "\n",
    "v1 = glove_model['mad']\n",
    "v2 = glove_model['hatter']\n",
    "res2 = (v1+v2)/2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Find the cosine similarity between these two phrases\n",
    "\n",
    "```python \n",
    "model.wv.cosine_similarities(res1, [res2])\n",
    "```\n",
    "\n",
    "Has the cosine similarity changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the cosine similarity between the two phrases \"**mad hatter**\" and \"**white rabbit**\" is far lower from the GloVe model. This is because the GloVe model hasn't seen the terms together in its training data as much as they appear in the book. In the book, the terms **mad** and **hatter** appear together a lot because they form the name of an important character. In other contexts, of course, we don't see **mad** and **hatter** together as often."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
